{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd9bf759-9b31-4a73-a87d-f3aee2bebfe1",
   "metadata": {},
   "source": [
    "# Part 1: Preprocessing\n",
    "\n",
    "## Preprocessing Categorical Variables\n",
    "\n",
    "In machine learning, most algorithms require numerical input data, so categorical data must be converted into a numerical format. Two common approaches for this are label encoding and one-hot encoding. We learnt both methods in `Unit 1.8`, let's do a recap.\n",
    "\n",
    "### Label Encoding\n",
    "\n",
    "Label encoding is a simple and straightforward method where each unique category value is assigned an integer value.\n",
    "\n",
    "**How it Works**\n",
    "\n",
    "For example, if you have a `color` feature with three categories: `red`, `green`, and `blue`, label encoding would replace them with `0`, `1`, and `2`, respectively.\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "Label encoding is ideal for ordinal data, where the categories have some inherent order. However, using this method on nominal data (no intrinsic order) can introduce a new problem: the model might assume a natural ordering between categories which may result in poor performance or unexpected results.\n",
    "\n",
    "We can implement label encoding and one-hot encoding using `pandas` or `scikit-learn`.\n",
    "### One-Hot Encoding\n",
    "\n",
    "One-hot encoding converts categorical values into a binary vector representation where only one bit is set to `1` out of all the bits representing the categories.\n",
    "\n",
    "**How it Works**\n",
    "\n",
    "Taking the same `color` example: for `red`, `green`, and `blue`, one-hot encoding would create three features, `is_red`, `is_green`, and `is_blue`. If the color is `red`, the corresponding feature `is_red` would be `1`, and the rest would be `0`: `red` = `[1, 0, 0]`, `green` = `[0, 1, 0]`, `blue` = `[0, 0, 1]`.\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "One-hot encoding is best used for nominal data where no ordinal relationship exists. The downside is that it can lead to a high-dimensional feature space, which might be problematic for models that struggle with high dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5921878f",
   "metadata": {},
   "source": [
    "### 1. Encoding with Pandas\n",
    "\n",
    "This section demonstrates the quickest way to encode categorical data using built-in pandas functionality. This approach is often used for quick data analysis or preprocessing before modeling.\n",
    "\n",
    "**Label Encoding**: Achieved by converting the column to the 'category' data type and accessing the numerical codes.\n",
    "\n",
    "**One-Hot Encoding**: Achieved using the pd.get_dummies() function, which automatically creates new binary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a99f1c4-d2ea-4703-94f1-004a05228ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>color_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  color_encoded\n",
       "0    red              2\n",
       "1  green              1\n",
       "2   blue              0\n",
       "3  green              1\n",
       "4    red              2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a DataFrame and perform label encoding on the 'color' \n",
    "# column using pandas category codes.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'color': ['red', 'green', 'blue', 'green', 'red']\n",
    "})\n",
    "df['color_encoded'] = df['color'].astype('category').cat.codes\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8b5022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color_encoded</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color_encoded  color_blue  color_green  color_red\n",
       "0              2       False        False       True\n",
       "1              1       False         True      False\n",
       "2              0        True        False      False\n",
       "3              1       False         True      False\n",
       "4              2       False        False       True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform one-hot encoding on the 'color' column using pandas get_dummies.\n",
    "\n",
    "df_one_hot = pd.get_dummies(df, columns=['color'])\n",
    "display(df_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38c94d",
   "metadata": {},
   "source": [
    "### 2. Encoding with Scikit-Learn\n",
    "\n",
    "This approach uses scikit-learn preprocessing classes. This is the standard method for machine learning pipelines because it allows you to fit the encoder on training data and consistently transform future test data.\n",
    "\n",
    "**LabelEncoder**: Converts labels into integers. Note: In sklearn, this is technically designed for target labels (y), but is often used for simple ordinal encoding of features (X).\n",
    "\n",
    "**OneHotEncoder**: The standard transformer for creating binary variables from categorical features. It expects 2D array inputs and can output sparse matrices to save memory (disabled here with sparse_output=False for readability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb15ca8-58f6-4cf2-bfc9-5a46b1606b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>color_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  color_encoded\n",
       "0    red              2\n",
       "1  green              1\n",
       "2   blue              0\n",
       "3  green              1\n",
       "4    red              2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Use scikit-learn's LabelEncoder to convert categorical 'color' \n",
    "# labels into numerical codes within a DataFrame.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'color': ['red', 'green', 'blue', 'green', 'red']\n",
    "})\n",
    "le = LabelEncoder()\n",
    "df['color_encoded'] = le.fit_transform(df['color'])\n",
    "df['color_encoded'] = le.fit_transform(df['color'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3aa60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color_blue  color_green  color_red\n",
       "0         0.0          0.0        1.0\n",
       "1         0.0          1.0        0.0\n",
       "2         1.0          0.0        0.0\n",
       "3         0.0          1.0        0.0\n",
       "4         0.0          0.0        1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply One-Hot Encoding to the 'color' feature using scikit-learn to generate a binary feature DataFrame.\n",
    "\n",
    "colors = df['color'].values.reshape(-1, 1)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "colors_encoded = encoder.fit_transform(colors)\n",
    "\n",
    "# Convert encoded features into a pandas DataFrame with descriptive column names from the encoder.\n",
    "\n",
    "df_one_hot_sklearn = pd.DataFrame(\n",
    "    colors_encoded, \n",
    "    columns=encoder.get_feature_names_out(['color'])\n",
    ")\n",
    "display(df_one_hot_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c115f",
   "metadata": {},
   "source": [
    "## Preprocessing Numerical Variables\n",
    "\n",
    "Preprocessing numerical variables is crucial to ensure that models perform optimally. Common techniques for preprocessing numerical data includes scaling, normalization, and handling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac59c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2\n",
       "0         1         4\n",
       "1         2         5\n",
       "2         3         6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "\n",
    "\n",
    "# Initialize a pandas DataFrame from a dictionary to structure feature data as a table.\n",
    "\n",
    "data = { 'feature1': [1, 2, 3],\n",
    "         'feature2': [4, 5, 6]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d871c-a6c6-447e-b320-51f02dff2a32",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "Scaling adjusts the range of data so that different features contribute equally to the final prediction. It's essential when using algorithms that are sensitive to the magnitude of the variables, such as Support Vector Machines (SVM) or K-nearest neighbors (KNN).\n",
    "\n",
    "**Standardization**\n",
    "\n",
    "Standardization rescales data to have a mean (μ) of 0 and standard deviation (σ) of 1 (unit variance).\n",
    "\n",
    "$$ x' = \\frac{x - \\mu}{\\sigma} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4303029d-e399-4d80-a27a-fc3ef0c1254d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.224745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2\n",
       "0 -1.224745 -1.224745\n",
       "1  0.000000  0.000000\n",
       "2  1.224745  1.224745"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the dataset features using scikit-learn's StandardScaler and reconstruct the DataFrame.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf16e0e",
   "metadata": {},
   "source": [
    "**Min-Max Scaling**\n",
    "\n",
    "Min-max scaling rescales the feature to a fixed range, usually 0 to 1.\n",
    "\n",
    "$$ x' = \\frac{x - \\text{min}(x)}{\\text{max}(x) - \\text{min}(x)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffef040-5f45-4b62-a87f-412d9611407d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2\n",
       "0       0.0       0.0\n",
       "1       0.5       0.5\n",
       "2       1.0       1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale dataset features to a fixed range (typically 0 to 1) using MinMaxScaler and reconstruct the DataFrame.\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df_minmax = pd.DataFrame(minmax_scaler.fit_transform(df), columns=df.columns)\n",
    "df_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61be4440",
   "metadata": {},
   "source": [
    "**Normalization**\n",
    "\n",
    "Adjusts the \"direction\" of your data rather than its \"magnitude.\" Imagine each data sample is an arrow pointing from the origin. Some arrows are very long (large values), and some are short (small values). Normalization shrinks or stretches every arrow so they all have the exact same length (usually 1), while keeping them pointing in the original direction.\n",
    "\n",
    "This ensures that the patterns (ratios between features) matter more than the raw counts or volumes.\n",
    "\n",
    "**L2 Normalization**\n",
    "\n",
    "In `scikit-learn`, the `Normalizer()`function defaults to L2 normalization which uses the \"straight-line\" distance (Euclidean). It squares every number in the row, adds them up, takes the square root and then divides every number by that total.\n",
    "\n",
    "$$x' = \\frac{x}{\\sum |x_i|} = \\frac{x}{||x||_1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235a3878-1d6a-4fe5-b76f-a39ee1413d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.242536</td>\n",
       "      <td>0.970143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371391</td>\n",
       "      <td>0.928477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.894427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2\n",
       "0  0.242536  0.970143\n",
       "1  0.371391  0.928477\n",
       "2  0.447214  0.894427"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the dataset row-wise and return the result as a DataFrame with original column names.\n",
    "# By default (norm='l2'), this scales each *row* (sample) individually to have a unit norm.\n",
    "\n",
    "normalizer = Normalizer() \n",
    "df_normalized = pd.DataFrame(normalizer.fit_transform(df), columns=df.columns)\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6e630",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "Missing values can significantly affect the performance of machine learning models. Common strategies for handling missing data include imputation and removing records with missing values. You've learnt about this in `Unit 1.8`.\n",
    "\n",
    "**Imputation**\n",
    "\n",
    "Imputation fills in missing values with a specific value, such as the mean, median, or mode of the column.\n",
    "\n",
    "**Removing Missing Values**\n",
    "\n",
    "If the dataset has only a few missing values, it might be reasonable to drop those records. However, this can lead to loss of valuable data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93fc1b-1cdd-4fa0-a6b1-24d4dc2b9559",
   "metadata": {},
   "source": [
    "You learnt about handling missing data using `pandas` in `Unit 1.8`, `sklearn` also provides utilities to deal with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae1d8a5-daa7-4d0b-86ad-0b6d31d49222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2\n",
       "0       1.0       4.0\n",
       "1       2.0       NaN\n",
       "2       NaN       6.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Initialize a pandas DataFrame from a dictionary, handling missing values as NaNs.\n",
    "\n",
    "data_with_missing = {'feature1': [1, 2, None], 'feature2': [4, None, 6]}\n",
    "df_missing = pd.DataFrame(data_with_missing)\n",
    "\n",
    "# Display the DataFrame to see the missing values (NaN)\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c922cb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2\n",
       "0       1.0       4.0\n",
       "1       2.0       5.0\n",
       "2       1.5       6.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values in the DataFrame using the mean strategy and reconstruct with original column names.\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_missing), columns=df_missing.columns)\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e58683e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Generate synthetic classification data, partition into train/test sets, and train a Logistic Regression model.\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce755d4",
   "metadata": {},
   "source": [
    "We will use several key metrics:\n",
    "\n",
    "- **Confusion Matrix**: A table showing true positives, false positives, true negatives, and false negatives.\n",
    "\n",
    "- **Accuracy**: The overall percentage of correct predictions.\n",
    "\n",
    "- **Precision & Recall**: Precision measures how many selected items are relevant, while Recall measures how many relevant items are selected.\n",
    "\n",
    "- **F1 Score** : The harmonic mean of precision and recall, useful when class distribution is uneven.\n",
    "\n",
    "- **ROC Curve & AUC**: The Receiver Operating Characteristic curve plots the True Positive Rate against the False Positive Rate at various threshold settings. AUC (Area Under the Curve) represents the degree of separability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f5e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "# Generate class predictions (0 or 1) and probability predictions (0.0 to 1.0)\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "# Calculate performance metrics\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculate ROC curve points and Area Under the Curve (AUC)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d946065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 90   3]\n",
      " [  4 103]]\n",
      "Accuracy: 0.96\n",
      "Precision: 0.97\n",
      "Recall: 0.96\n",
      "F1 Score: 0.97\n",
      "AUC: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"AUC: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f37060-4c81-436f-a523-c262a0b5a413",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Accuracy is the most intuitive performance measure. It is simply the ratio of correctly predicted observations to the total observations.\n",
    "\n",
    "$$ \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Observations}} $$\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "Accuracy is best used when the target classes are well balanced. However, it can be misleading when dealing with imbalanced datasets.\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table that is used to describe the performance of a classification model on a set of test data for which the true values are known.\n",
    "\n",
    "**Components**\n",
    "\n",
    "![confusion-matrix](../assets/confusion-matrix.png)\n",
    "\n",
    "- True Positive (TP): Correctly predicted positives\n",
    "- True Negative (TN): Correctly predicted negatives\n",
    "- False Positive (FP): Incorrectly predicted positives (Type I error)\n",
    "- False Negative (FN): Incorrectly predicted negatives (Type II error)\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "The confusion matrix is not a metric but a helpful tool for computing various metrics and gaining a more detailed insight into where the model is making errors.\n",
    "\n",
    "### Precision\n",
    "\n",
    "Precision is the ratio of correctly predicted positive observations to the total predicted positive observations.\n",
    "\n",
    "$$ \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $$\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "Use precision when the cost of a false positive is high, such as in spam email detection.\n",
    "\n",
    "### Recall (also known as True Positve Rate or Sensitivity)\n",
    "\n",
    "Recall is the ratio of correctly predicted positive observations to all observations in the actual class.\n",
    "\n",
    "$$ \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $$\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "Use recall when the cost of a false negative is high, such as in fraud detection.\n",
    "\n",
    "### Specificity (also known as True Negative Rate)\n",
    "\n",
    "Specificity measures the proportion of actual negatives that are correctly identified as such. It complements recall (sensitivity) by focusing on the model's performance with the negative class.\n",
    "\n",
    "$$ \\text{Specificity} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}} $$\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "Specificity is particularly important in situations where the cost of a false positive is high. For example, in medical diagnostics, a false positive might lead to unnecessary treatment, which could be costly or harmful.\n",
    "\n",
    "### F1 Score\n",
    "\n",
    "The F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account.\n",
    "\n",
    "$$ \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "Use the F1 score when you want to balance precision and recall, especially if there is an uneven class distribution.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
